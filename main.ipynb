{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT64le2KMjr6"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle-gpu==2.6.2 -f https://www.paddlepaddle.org.cn/whl/cu118.html\n",
        "!pip install paddleocr\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from paddleocr import PaddleOCR\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "# Initialize PaddleOCR with GPU support\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')  # Set the language model as needed\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs('/content/download', exist_ok=True)\n",
        "os.makedirs('/content/processed', exist_ok=True)\n",
        "\n",
        "def download_images(image_links, batch_number):\n",
        "    \"\"\"Download images from given links and save them to the specified folder.\"\"\"\n",
        "    image_paths = []\n",
        "    for i, link in enumerate(image_links):\n",
        "        try:\n",
        "            response = requests.get(link)\n",
        "            response.raise_for_status()\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            img_path = f'/content/download/image_{batch_number*40 + i + 1}.jpg'\n",
        "            img.save(img_path)\n",
        "            image_paths.append(img_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {link}: {e}\")\n",
        "    return image_paths\n",
        "\n",
        "def process_images():\n",
        "    \"\"\"Process images in batches and save results to CSV.\"\"\"\n",
        "    # Read the CSV file\n",
        "    train_df = pd.read_csv('/content/test.csv')\n",
        "    num_batches = (len(train_df) + 39) // 40\n",
        "\n",
        "    with open('/content/processed_image.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['image_link', 'group_id', 'entity_name', 'text_gainedfromocr'])\n",
        "\n",
        "        for batch_number in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
        "            # Get the image links for the current batch\n",
        "            start_idx = batch_number * 40\n",
        "            end_idx = min(start_idx + 40, len(train_df))\n",
        "            batch_df = train_df.iloc[start_idx:end_idx]\n",
        "\n",
        "            # Download images\n",
        "            image_paths = download_images(batch_df['image_link'].tolist(), batch_number)\n",
        "\n",
        "            # Process images with PaddleOCR\n",
        "            for i, img_path in enumerate(image_paths):\n",
        "                try:\n",
        "                    result = ocr.ocr(img_path, cls=True)\n",
        "\n",
        "                    # Check and handle OCR results\n",
        "                    if result is None or not result:\n",
        "                        text = \"\"\n",
        "                    else:\n",
        "                        text = ' '.join([line[1][0] for line in result[0]])\n",
        "\n",
        "                    # Write the results to the CSV\n",
        "                    row = [\n",
        "                        batch_df.iloc[i]['image_link'],\n",
        "                        batch_df.iloc[i]['group_id'],\n",
        "                        batch_df.iloc[i]['entity_name'],\n",
        "                        text\n",
        "                    ]\n",
        "                    writer.writerow(row)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during OCR processing for image {img_path}: {e}\")\n",
        "                    # Write empty result in case of error\n",
        "                    row = [\n",
        "                        batch_df.iloc[i]['image_link'],\n",
        "                        batch_df.iloc[i]['group_id'],\n",
        "                        batch_df.iloc[i]['entity_name'],\n",
        "                        \"\"\n",
        "                    ]\n",
        "                    writer.writerow(row)\n",
        "\n",
        "                # Remove the image after processing\n",
        "                os.remove(img_path)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    process_images()\n"
      ],
      "metadata": {
        "id": "vYbUz5dZMl8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Unit conversion dictionary (to centimetres, grams, etc.)\n",
        "unit_conversion = {\n",
        "    'cm': 1,\n",
        "    'centimetre': 1,\n",
        "    'centimeter': 1,\n",
        "    'mm': 0.1,\n",
        "    'millimeter': 0.1,\n",
        "    'inch': 2.54,\n",
        "    'in': 2.54,\n",
        "    'foot': 30.48,\n",
        "    'ft': 30.48,\n",
        "    'yard': 91.44,\n",
        "    \"'\": 2.54,  # sometimes inches are written as single quotes\n",
        "    'm': 100,\n",
        "    'metre': 100,\n",
        "    'g': 1,\n",
        "    'gram': 1,\n",
        "    'kg': 1000,\n",
        "    'kilogram': 1000,\n",
        "    'lb': 453.59237,\n",
        "    'lbs': 453.59237,\n",
        "    'oz': 28.3495,\n",
        "    'w': 1,  # Wattage doesn't need conversion\n",
        "    'watt': 1\n",
        "}\n",
        "\n",
        "# Regular expression patterns for different units\n",
        "value_unit_pattern = re.compile(r'(\\d*\\.?\\d+)\\s*(cm|mm|in|inch|foot|ft|yard|m|\\'|metre|centimetre|centimeter|g|gram|kg|kilogram|lb|lbs|oz|w|watt)', re.IGNORECASE)\n",
        "\n",
        "# Define the entity-unit map\n",
        "entity_unit_map = {\n",
        "    \"width\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
        "    \"depth\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
        "    \"height\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n",
        "    \"item_weight\": {\"milligram\", \"kilogram\", \"microgram\", \"gram\", \"ounce\", \"ton\", \"pound\"},\n",
        "    \"maximum_weight_recommendation\": {\"milligram\", \"kilogram\", \"microgram\", \"gram\", \"ounce\", \"ton\", \"pound\"},\n",
        "    \"voltage\": {\"millivolt\", \"kilovolt\", \"volt\"},\n",
        "    \"wattage\": {\"kilowatt\", \"watt\"},\n",
        "    \"item_volume\": {\"cubic foot\", \"microlitre\", \"cup\", \"fluid ounce\", \"centilitre\", \"imperial gallon\", \"pint\",\n",
        "                    \"decilitre\", \"litre\", \"millilitre\", \"quart\", \"cubic inch\", \"gallon\"}\n",
        "}\n",
        "\n",
        "# Function to convert unit to centimetre or gram and return the value\n",
        "def convert_to_cm_or_gram(value, unit):\n",
        "    unit = unit.lower().strip()\n",
        "    if unit in unit_conversion:\n",
        "        try:\n",
        "            return float(value) * unit_conversion[unit]\n",
        "        except ValueError:\n",
        "            # Skip invalid numeric strings like '240 V 16 A'\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "# Function to convert watts from volts and amps\n",
        "def convert_wattage(volts, amps):\n",
        "    try:\n",
        "        volts = float(volts)\n",
        "        amps = float(amps)\n",
        "        return volts * amps\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "# Function to extract and compare dimensions while keeping original values and units\n",
        "def extract_dimensions(text):\n",
        "    if not text or not isinstance(text, str):\n",
        "        return None, None, None, None  # Handle null or non-string values\n",
        "\n",
        "    # Extract all values and units\n",
        "    matches = value_unit_pattern.findall(text)\n",
        "\n",
        "    # Prepare lists for original values and converted values\n",
        "    original_values = []\n",
        "    values_in_cm_or_gram = []\n",
        "\n",
        "    # Convert all extracted values to centimetres or grams for comparison, but keep the original values\n",
        "    for value, unit in matches:\n",
        "        original_values.append((value, unit))\n",
        "        converted_value = convert_to_cm_or_gram(value, unit)\n",
        "        if converted_value is not None:\n",
        "            values_in_cm_or_gram.append(converted_value)\n",
        "\n",
        "    # Check for volts and amps in various formats (for wattage calculation)\n",
        "    volt_amp_matches = re.findall(r'(\\d*\\.?\\d+)\\s*(V|volt|volts|v)\\s*[\\D]*\\s*(\\d*\\.?\\d+)\\s*(A|amp|amps|a)', text, re.IGNORECASE)\n",
        "    if volt_amp_matches:\n",
        "        volts, _, amps, _ = volt_amp_matches[0]\n",
        "        wattage_value = convert_wattage(volts, amps)\n",
        "        if wattage_value is not None:\n",
        "            values_in_cm_or_gram.append(wattage_value)\n",
        "            original_values.append((f\"{volts} V {amps} A\", 'watt'))\n",
        "\n",
        "    # Sort the converted values to determine height, width, depth, and weight (highest, medium, lowest)\n",
        "    sorted_values_in_cm_or_gram = sorted(values_in_cm_or_gram, reverse=True)  # Reverse to get highest first\n",
        "\n",
        "    # If fewer than 4 values, repeat the smaller values to fill width, depth, and weight\n",
        "    if len(sorted_values_in_cm_or_gram) >= 4:\n",
        "        height, width, depth, weight = sorted_values_in_cm_or_gram[0], sorted_values_in_cm_or_gram[1], sorted_values_in_cm_or_gram[2], sorted_values_in_cm_or_gram[3]\n",
        "    elif len(sorted_values_in_cm_or_gram) == 3:\n",
        "        height, width, depth, weight = sorted_values_in_cm_or_gram[0], sorted_values_in_cm_or_gram[1], sorted_values_in_cm_or_gram[2], sorted_values_in_cm_or_gram[0]\n",
        "    elif len(sorted_values_in_cm_or_gram) == 2:\n",
        "        height, width, depth, weight = sorted_values_in_cm_or_gram[0], sorted_values_in_cm_or_gram[1], sorted_values_in_cm_or_gram[1], sorted_values_in_cm_or_gram[1]\n",
        "    elif len(sorted_values_in_cm_or_gram) == 1:\n",
        "        height, width, depth, weight = sorted_values_in_cm_or_gram[0], sorted_values_in_cm_or_gram[0], sorted_values_in_cm_or_gram[0], sorted_values_in_cm_or_gram[0]\n",
        "    else:\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Match the original values with the sorted converted values and form the result\n",
        "    height_original = next((v for v in original_values if convert_to_cm_or_gram(*v) == height), None)\n",
        "    width_original = next((v for v in original_values if convert_to_cm_or_gram(*v) == width), None)\n",
        "    depth_original = next((v for v in original_values if convert_to_cm_or_gram(*v) == depth), None)\n",
        "    weight_original = next((v for v in original_values if convert_to_cm_or_gram(*v) == weight), None)\n",
        "\n",
        "    return height_original, width_original, depth_original, weight_original\n",
        "\n",
        "# Function to map the extracted values to the desired unit for each entity\n",
        "def map_to_entity_unit(entity_name, original_unit):\n",
        "    allowed_units = entity_unit_map.get(entity_name, set())\n",
        "    # If original unit is in allowed units, return it, otherwise return the first allowed unit\n",
        "    if original_unit in allowed_units:\n",
        "        return original_unit\n",
        "    elif allowed_units:\n",
        "        return next(iter(allowed_units))  # Return any allowed unit as fallback\n",
        "    return original_unit\n",
        "\n",
        "# Function to process the CSV and extract the required information\n",
        "def process_csv(file_path):\n",
        "    # Load the CSV into a pandas dataframe\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Create empty columns for the new results\n",
        "    df['newcol'] = None\n",
        "    df['unit_col'] = None\n",
        "\n",
        "    # Iterate over each row in the dataframe\n",
        "    for index, row in df.iterrows():\n",
        "        # Extract dimensions from the text_gainedfromocr\n",
        "        height_original, width_original, depth_original, weight_original = extract_dimensions(row.get('text_gainedfromocr'))\n",
        "\n",
        "        # Determine which value to store based on entity_name and map it to appropriate unit\n",
        "        if row['entity_name'] == 'height' and height_original:\n",
        "            df.at[index, 'newcol'] = float(height_original[0])\n",
        "            df.at[index, 'unit_col'] = map_to_entity_unit(row['entity_name'], height_original[1])\n",
        "        elif row['entity_name'] == 'width' and width_original:\n",
        "            df.at[index, 'newcol'] = float(width_original[0])\n",
        "            df.at[index, 'unit_col'] = map_to_entity_unit(row['entity_name'], width_original[1])\n",
        "        elif row['entity_name'] == 'depth' and depth_original:\n",
        "            df.at[index, 'newcol'] = float(depth_original[0])\n",
        "            df.at[index, 'unit_col'] = map_to_entity_unit(row['entity_name'], depth_original[1])\n",
        "        elif row['entity_name'] == 'item_weight' and weight_original:\n",
        "            df.at[index, 'newcol'] = float(weight_original[0])\n",
        "            df.at[index, 'unit_col'] = map_to_entity_unit(row['entity_name'], weight_original[1])\n",
        "        elif row['entity_name'] == 'wattage':\n",
        "            # Handle wattage directly from the regex for wattage\n",
        "            wattage_matches = re.findall(r'(\\d*\\.?\\d+)\\s*(w|watt)', str(row.get('text_gainedfromocr')), re.IGNORECASE)\n",
        "            if wattage_matches:\n",
        "                wattage_original = wattage_matches[0]  # Get the first wattage match\n",
        "                df.at[index, 'newcol'] = float(wattage_original[0])\n",
        "                df.at[index, 'unit_col'] = map_to_entity_unit(row['entity_name'], wattage_original[1])\n",
        "            else:\n",
        "                # Handle volt and amp conversion\n",
        "                volt_amp_matches = re.findall(r'(\\d*\\.?\\d+)\\s*(V|volt|volts|v)\\s*[\\D]*\\s*(\\d*\\.?\\d+)\\s*(A|amp|amps|a)', str(row.get('text_gainedfromocr')), re.IGNORECASE)\n",
        "                if volt_amp_matches:\n",
        "                    volts, _, amps, _ = volt_amp_matches[0]\n",
        "                    wattage_value = convert_wattage(volts, amps)\n",
        "                    if wattage_value is not None:\n",
        "                        df.at[index, 'newcol'] = float(wattage_value)\n",
        "                        df.at[index, 'unit_col'] = map_to_entity_unit(row['entity_name'], 'watt')\n",
        "\n",
        "    # Save the dataframe with the new columns to a new CSV file\n",
        "    output_file = 'processed_output.csv'\n",
        "    df.to_csv(output_file, index=False)\n",
        "    return output_file\n",
        "\n",
        "# Usage\n",
        "csv_file = '/content/processed_image.csv'  # Provide the path to the CSV file\n",
        "output_file = process_csv(csv_file)\n",
        "print(f'Processed data saved to: {output_file}')\n"
      ],
      "metadata": {
        "id": "PNSwOVmLMqv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/processed_output.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "id": "RIs9asjzM78r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_predictions(input_file, output_file):\n",
        "    # Load the input CSV file\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Create an empty list to store predictions\n",
        "    predictions = []\n",
        "\n",
        "    # Iterate over each row in the dataframe\n",
        "    for index, row in df.iterrows():\n",
        "        # Extract the float value (newcol) and unit (unit_col)\n",
        "        value = row.get('newcol')\n",
        "        unit = row.get('unit_col')\n",
        "\n",
        "        # Initialize the prediction string as empty\n",
        "        prediction = \"\"\n",
        "\n",
        "        # Check if both value and unit are available and valid\n",
        "        if pd.notnull(value) and pd.notnull(unit):\n",
        "            try:\n",
        "                # Format the value as a float in standard notation\n",
        "                formatted_value = f\"{float(value):.6g}\"  # This ensures it is in standard float notation\n",
        "                # Concatenate value and unit with a space\n",
        "                prediction = f\"{formatted_value} {unit.strip()}\"\n",
        "            except ValueError:\n",
        "                # If conversion to float fails, leave prediction as empty\n",
        "                prediction = \"\"\n",
        "\n",
        "        # Append the prediction to the list\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    # Create a new dataframe for output\n",
        "    output_df = pd.DataFrame({\n",
        "        'index': df['index'],\n",
        "        'prediction': predictions\n",
        "    })\n",
        "\n",
        "    # Save the output dataframe to a new CSV file\n",
        "    output_df.to_csv(output_file, index=False)\n",
        "\n",
        "# File paths\n",
        "input_file = 'test_with_val_final.csv'  # Input CSV file path\n",
        "output_file = 'predictions_output.csv'  # Output CSV file path\n",
        "\n",
        "# Process the input file and save the predictions\n",
        "process_predictions(input_file, output_file)\n",
        "\n",
        "print(f\"Processed predictions saved to: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up1Urn4IQX1P",
        "outputId": "37e6aef7-2e05-48d2-da7a-854e34e49bc5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed predictions saved to: predictions_output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIUtF90TQn0c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TMnRGOALRcG_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}